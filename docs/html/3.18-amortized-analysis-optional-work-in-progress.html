<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-GB" xml:lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Cliff Shaffer" />
  <meta name="author" content="Peter Ljunglöf" />
  <meta name="author" content="Nick Smallbone" />
  <title>DSABook – Amortized Analysis (optional) (WORK IN
PROGRESS)</title>
  <style>
    div.sitenav { display: flex; flex-direction: row; flex-wrap: wrap; }
    span.navlink { flex: 1; }
    span.navlink-label { display: inline-block; min-width: 4em; }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        background-color: #ffffff;
        color: #a0a0a0;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
    div.sourceCode
      { color: #1f1c1b; background-color: #ffffff; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #1f1c1b; } /* Normal */
    code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
    code span.an { color: #ca60ca; } /* Annotation */
    code span.at { color: #0057ae; } /* Attribute */
    code span.bn { color: #b08000; } /* BaseN */
    code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
    code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #924c9d; } /* Char */
    code span.cn { color: #aa5500; } /* Constant */
    code span.co { color: #898887; } /* Comment */
    code span.cv { color: #0095ff; } /* CommentVar */
    code span.do { color: #607880; } /* Documentation */
    code span.dt { color: #0057ae; } /* DataType */
    code span.dv { color: #b08000; } /* DecVal */
    code span.er { color: #bf0303; text-decoration: underline; } /* Error */
    code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
    code span.fl { color: #b08000; } /* Float */
    code span.fu { color: #644a9b; } /* Function */
    code span.im { color: #ff5500; } /* Import */
    code span.in { color: #b08000; } /* Information */
    code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
    code span.op { color: #1f1c1b; } /* Operator */
    code span.ot { color: #006e28; } /* Other */
    code span.pp { color: #006e28; } /* Preprocessor */
    code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
    code span.sc { color: #3daee9; } /* SpecialChar */
    code span.ss { color: #ff5500; } /* SpecialString */
    code span.st { color: #bf0303; } /* String */
    code span.va { color: #0057ae; } /* Variable */
    code span.vs { color: #bf0303; } /* VerbatimString */
    code span.wa { color: #bf0303; } /* Warning */
  </style>
  <link rel="stylesheet" href="../bookstyle.css" />
  
  <link rel="stylesheet" href="../lib/JSAV.css" type="text/css" />
  <link rel="stylesheet" href="../lib/odsaMOD.css" type="text/css" />
  <link rel="stylesheet" href="../lib/jquery.ui.min.css" type="text/css" />
  <link rel="stylesheet" href="../lib/odsaStyle.css" type="text/css" />
  <link rel="stylesheet" href="../lib/ChalmersGU-interactive.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">


  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:    './',
      VERSION:     '0.4.1',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
      },
      "HTML-CSS": {
        scale: "80",
      }
    });
  </script>

  <script type="text/javascript" src="../lib/jquery.min.js"></script>
  <script type="text/javascript" src="../lib/jquery.migrate.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/javascript" src="../lib/localforage.min.js"></script>
  <script type="text/javascript" src="../lib/accessibility.js"></script>
  <script type="text/javascript" src="../lib/jquery.ui.min.js"></script>
  <script type="text/javascript" src="../lib/jquery.transit.js"></script>
  <script type="text/javascript" src="../lib/raphael.js"></script>
  <script type="text/javascript" src="../lib/JSAV.js"></script>
  <script type="text/javascript" src="../lib/config.js"></script>
  <script type="text/javascript" src="../lib/timeme.js"></script>
  <script type="text/javascript" src="../lib/odsaUtils.js"></script>
  <script type="text/javascript" src="../lib/odsaMOD.js"></script>
  <script type="text/javascript" src="../lib/d3.min.js"></script>
  <script type="text/javascript" src="../lib/d3-selection-multi.v1.min.js"></script>
  <script type="text/javascript" src="../lib/dataStructures.js"></script>
  <script type="text/javascript" src="../lib/conceptMap.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.min.js" integrity="sha384-BBtl+eGJRgqQAUMxJ7pMwbEyER4l1g+O15P+16Ep7Q9Q+zqX6gSbd85u4mG4QzX+" crossorigin="anonymous"></script>
  <script src="../scroll-toc.js"></script>

  <script>
    ODSA.SETTINGS.MODULE_SECTIONS = [
    'internal-variables', 
    'getting-and-setting-values', 
    'adding-elements', 
    'add-practice-exericse', 
    'removing-elements', 
    'remove-practice-exericise', 
    'static-array-based-list-summary-questions', 
    'static-array-based-list:-full-code',
    ];
    ODSA.SETTINGS.MODULE_NAME = "DSABook";
    ODSA.SETTINGS.MODULE_LONG_NAME = "Data Structures and Algorithms";
    JSAV_OPTIONS['lang']='en';
    JSAV_EXERCISE_OPTIONS['code']='pseudo';
  </script>

</head>
<body><div class="row">
<div class="col-3"><nav id="TOC" role="doc-toc" class="nav-scroll-header"><div class="nav-scroll">
<ul>
<li><a href="1-introduction.html#introduction"
id="toc-introduction"><span class="toc-section-number">1</span>
Introduction</a>
<ul>
<li><a
href="1.1-selecting-a-data-structure.html#selecting-a-data-structure"
id="toc-selecting-a-data-structure"><span
class="toc-section-number">1.1</span> Selecting a Data
Structure</a></li>
<li><a href="1.2-abstract-data-types.html#abstract-data-types"
id="toc-abstract-data-types"><span class="toc-section-number">1.2</span>
Abstract Data Types</a></li>
<li><a
href="1.3-all-adts-used-in-this-book.html#all-adts-used-in-this-book"
id="toc-all-adts-used-in-this-book"><span
class="toc-section-number">1.3</span> All ADTs Used in This
Book</a></li>
<li><a
href="1.4-information-retrieval-sets-and-maps.html#information-retrieval-sets-and-maps"
id="toc-information-retrieval-sets-and-maps"><span
class="toc-section-number">1.4</span> Information retrieval: Sets and
Maps</a></li>
<li><a
href="1.5-comparables-comparators-and-key-value-pairs.html#comparables-comparators-and-key-value-pairs"
id="toc-comparables-comparators-and-key-value-pairs"><span
class="toc-section-number">1.5</span> Comparables, Comparators and
Key-Value Pairs</a></li>
<li><a
href="1.6-comparables-and-comparators-an-example.html#comparables-and-comparators-an-example"
id="toc-comparables-and-comparators-an-example"><span
class="toc-section-number">1.6</span> Comparables and Comparators: An
Example</a></li>
</ul></li>
<li><a
href="2-arrays-searching-and-sorting.html#arrays-searching-and-sorting"
id="toc-arrays-searching-and-sorting"><span
class="toc-section-number">2</span> Arrays: searching and sorting</a>
<ul>
<li><a href="2.1-searching-in-an-array.html#searching-in-an-array"
id="toc-searching-in-an-array"><span
class="toc-section-number">2.1</span> Searching in an Array</a></li>
<li><a href="2.2-sorting.html#sorting" id="toc-sorting"><span
class="toc-section-number">2.2</span> Sorting</a></li>
<li><a
href="2.3-sorting-terminology-and-notation.html#sorting-terminology-and-notation"
id="toc-sorting-terminology-and-notation"><span
class="toc-section-number">2.3</span> Sorting Terminology and
Notation</a></li>
<li><a href="2.4-insertion-sort.html#insertion-sort"
id="toc-insertion-sort"><span class="toc-section-number">2.4</span>
Insertion Sort</a></li>
<li><a href="2.5-bubble-sort-optional.html#bubble-sort-optional"
id="toc-bubble-sort-optional"><span
class="toc-section-number">2.5</span> Bubble Sort (optional)</a></li>
<li><a href="2.6-selection-sort.html#selection-sort"
id="toc-selection-sort"><span class="toc-section-number">2.6</span>
Selection Sort</a></li>
<li><a
href="2.7-the-cost-of-exchange-sorting-optional.html#the-cost-of-exchange-sorting-optional"
id="toc-the-cost-of-exchange-sorting-optional"><span
class="toc-section-number">2.7</span> The Cost of Exchange Sorting
(optional)</a></li>
<li><a
href="2.8-optimizing-sort-algorithms-with-code-tuning-optional.html#optimizing-sort-algorithms-with-code-tuning-optional"
id="toc-optimizing-sort-algorithms-with-code-tuning-optional"><span
class="toc-section-number">2.8</span> Optimizing Sort Algorithms with
Code Tuning (optional)</a></li>
<li><a href="2.9-mergesort.html#mergesort" id="toc-mergesort"><span
class="toc-section-number">2.9</span> Mergesort</a></li>
<li><a href="2.10-implementing-mergesort.html#implementing-mergesort"
id="toc-implementing-mergesort"><span
class="toc-section-number">2.10</span> Implementing Mergesort</a></li>
<li><a href="2.11-quicksort.html#quicksort" id="toc-quicksort"><span
class="toc-section-number">2.11</span> Quicksort</a></li>
<li><a
href="2.12-an-empirical-comparison-of-sorting-algorithms.html#an-empirical-comparison-of-sorting-algorithms"
id="toc-an-empirical-comparison-of-sorting-algorithms"><span
class="toc-section-number">2.12</span> An Empirical Comparison of
Sorting Algorithms</a></li>
<li><a
href="2.13-lower-bounds-for-sorting-optional.html#lower-bounds-for-sorting-optional"
id="toc-lower-bounds-for-sorting-optional"><span
class="toc-section-number">2.13</span> Lower Bounds for Sorting
(optional)</a></li>
<li><a href="2.14-arrays-as-sets-or-maps.html#arrays-as-sets-or-maps"
id="toc-arrays-as-sets-or-maps"><span
class="toc-section-number">2.14</span> Arrays as Sets or Maps</a></li>
<li><a
href="2.15-sorting-summary-exercises.html#sorting-summary-exercises"
id="toc-sorting-summary-exercises"><span
class="toc-section-number">2.15</span> Sorting: Summary
Exercises</a></li>
</ul></li>
<li><a href="3-algorithm-analysis.html#algorithm-analysis"
id="toc-algorithm-analysis"><span class="toc-section-number">3</span>
Algorithm Analysis</a>
<ul>
<li><a
href="3.1-problems-algorithms-and-programs.html#problems-algorithms-and-programs"
id="toc-problems-algorithms-and-programs"><span
class="toc-section-number">3.1</span> Problems, Algorithms, and
Programs</a></li>
<li><a href="3.2-comparing-algorithms.html#comparing-algorithms"
id="toc-comparing-algorithms"><span
class="toc-section-number">3.2</span> Comparing Algorithms</a></li>
<li><a
href="3.3-best-worst-and-average-cases.html#best-worst-and-average-cases"
id="toc-best-worst-and-average-cases"><span
class="toc-section-number">3.3</span> Best, Worst, and Average
Cases</a></li>
<li><a
href="3.4-faster-computer-or-faster-algorithm.html#faster-computer-or-faster-algorithm"
id="toc-faster-computer-or-faster-algorithm"><span
class="toc-section-number">3.4</span> Faster Computer, or Faster
Algorithm?</a></li>
<li><a
href="3.5-asymptotic-analysis-and-upper-bounds.html#asymptotic-analysis-and-upper-bounds"
id="toc-asymptotic-analysis-and-upper-bounds"><span
class="toc-section-number">3.5</span> Asymptotic Analysis and Upper
Bounds</a></li>
<li><a
href="3.6-lower-bounds-and-theta-notation.html#lower-bounds-and-theta-notation"
id="toc-lower-bounds-and-theta-notation"><span
class="toc-section-number">3.6</span> Lower Bounds and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Θ</mi><annotation encoding="application/x-tex">\Theta</annotation></semantics></math>
Notation</a></li>
<li><a
href="3.7-calculating-program-running-time.html#calculating-program-running-time"
id="toc-calculating-program-running-time"><span
class="toc-section-number">3.7</span> Calculating Program Running
Time</a></li>
<li><a href="3.8-analyzing-problems.html#analyzing-problems"
id="toc-analyzing-problems"><span class="toc-section-number">3.8</span>
Analyzing Problems</a></li>
<li><a href="3.9-common-misunderstandings.html#common-misunderstandings"
id="toc-common-misunderstandings"><span
class="toc-section-number">3.9</span> Common Misunderstandings</a></li>
<li><a href="3.10-multiple-parameters.html#multiple-parameters"
id="toc-multiple-parameters"><span
class="toc-section-number">3.10</span> Multiple Parameters</a></li>
<li><a href="3.11-space-bounds.html#space-bounds"
id="toc-space-bounds"><span class="toc-section-number">3.11</span> Space
Bounds</a></li>
<li><a
href="3.12-code-tuning-and-empirical-analysis.html#code-tuning-and-empirical-analysis"
id="toc-code-tuning-and-empirical-analysis"><span
class="toc-section-number">3.12</span> Code Tuning and Empirical
Analysis</a></li>
<li><a
href="3.13-algorithm-analysis-summary-exercises.html#algorithm-analysis-summary-exercises"
id="toc-algorithm-analysis-summary-exercises"><span
class="toc-section-number">3.13</span> Algorithm Analysis: Summary
Exercises</a></li>
<li><a href="3.14-summary-exercise-cs3.html#summary-exercise-cs3"
id="toc-summary-exercise-cs3"><span
class="toc-section-number">3.14</span> Summary Exercise: CS3</a></li>
<li><a
href="3.15-growth-rates-review-optional-work-in-progress.html#growth-rates-review-optional-work-in-progress"
id="toc-growth-rates-review-optional-work-in-progress"><span
class="toc-section-number">3.15</span> Growth Rates Review (optional)
(WORK IN PROGRESS)</a></li>
<li><a
href="3.16-summation-techniques-optional-work-in-progress.html#summation-techniques-optional-work-in-progress"
id="toc-summation-techniques-optional-work-in-progress"><span
class="toc-section-number">3.16</span> Summation Techniques (optional)
(WORK IN PROGRESS)</a></li>
<li><a
href="3.17-solving-recurrence-relations-optional-work-in-progress.html#solving-recurrence-relations-optional-work-in-progress"
id="toc-solving-recurrence-relations-optional-work-in-progress"><span
class="toc-section-number">3.17</span> Solving Recurrence Relations
(optional) (WORK IN PROGRESS)</a></li>
<li><a
href="3.18-amortized-analysis-optional-work-in-progress.html#amortized-analysis-optional-work-in-progress"
id="toc-amortized-analysis-optional-work-in-progress"><span
class="toc-section-number">3.18</span> Amortized Analysis (optional)
(WORK IN PROGRESS)</a></li>
</ul></li>
<li><a href="4-lists-1.html#lists-1" id="toc-lists-1"><span
class="toc-section-number">4</span> Lists</a>
<ul>
<li><a href="4.1-the-list-adt.html#the-list-adt"
id="toc-the-list-adt"><span class="toc-section-number">4.1</span> The
List ADT</a></li>
<li><a href="4.2-static-array-based-lists.html#static-array-based-lists"
id="toc-static-array-based-lists"><span
class="toc-section-number">4.2</span> Static Array-Based Lists</a></li>
<li><a
href="4.3-dynamic-array-based-lists.html#dynamic-array-based-lists"
id="toc-dynamic-array-based-lists"><span
class="toc-section-number">4.3</span> Dynamic Array-Based Lists</a></li>
<li><a href="4.4-linked-lists.html#linked-lists"
id="toc-linked-lists"><span class="toc-section-number">4.4</span> Linked
Lists</a></li>
<li><a
href="4.5-comparison-of-list-implementations.html#comparison-of-list-implementations"
id="toc-comparison-of-list-implementations"><span
class="toc-section-number">4.5</span> Comparison of List
Implementations</a></li>
<li><a
href="4.6-implementing-maps-using-lists.html#implementing-maps-using-lists"
id="toc-implementing-maps-using-lists"><span
class="toc-section-number">4.6</span> Implementing Maps using
Lists</a></li>
<li><a
href="4.7-doubly-linked-lists-optional.html#doubly-linked-lists-optional"
id="toc-doubly-linked-lists-optional"><span
class="toc-section-number">4.7</span> Doubly Linked Lists
(optional)</a></li>
<li><a href="4.8-stacks.html#stacks" id="toc-stacks"><span
class="toc-section-number">4.8</span> Stacks</a></li>
<li><a href="4.9-implementing-recursion.html#implementing-recursion"
id="toc-implementing-recursion"><span
class="toc-section-number">4.9</span> Implementing Recursion</a></li>
<li><a href="4.10-queues.html#queues" id="toc-queues"><span
class="toc-section-number">4.10</span> Queues</a></li>
<li><a
href="4.11-linear-structure-summary-exercises.html#linear-structure-summary-exercises"
id="toc-linear-structure-summary-exercises"><span
class="toc-section-number">4.11</span> Linear Structure Summary
Exercises</a></li>
</ul></li>
<li><a href="5-binary-trees.html#binary-trees"
id="toc-binary-trees"><span class="toc-section-number">5</span> Binary
Trees</a>
<ul>
<li><a
href="5.1-definitions-and-properties.html#definitions-and-properties"
id="toc-definitions-and-properties"><span
class="toc-section-number">5.1</span> Definitions and
Properties</a></li>
<li><a
href="5.2-binary-tree-as-a-recursive-data-structure.html#binary-tree-as-a-recursive-data-structure"
id="toc-binary-tree-as-a-recursive-data-structure"><span
class="toc-section-number">5.2</span> Binary Tree as a Recursive Data
Structure</a></li>
<li><a
href="5.3-binary-tree-node-implementations.html#binary-tree-node-implementations"
id="toc-binary-tree-node-implementations"><span
class="toc-section-number">5.3</span> Binary Tree Node
Implementations</a></li>
<li><a
href="5.4-the-full-binary-tree-theorem-optional.html#the-full-binary-tree-theorem-optional"
id="toc-the-full-binary-tree-theorem-optional"><span
class="toc-section-number">5.4</span> The Full Binary Tree Theorem
(optional)</a></li>
<li><a href="5.5-binary-tree-traversals.html#binary-tree-traversals"
id="toc-binary-tree-traversals"><span
class="toc-section-number">5.5</span> Binary Tree Traversals</a></li>
<li><a
href="5.6-implementing-tree-traversals.html#implementing-tree-traversals"
id="toc-implementing-tree-traversals"><span
class="toc-section-number">5.6</span> Implementing Tree
Traversals</a></li>
<li><a
href="5.7-information-flow-in-recursive-functions.html#information-flow-in-recursive-functions"
id="toc-information-flow-in-recursive-functions"><span
class="toc-section-number">5.7</span> Information Flow in Recursive
Functions</a></li>
<li><a
href="5.8-binary-tree-space-requirements-optional.html#binary-tree-space-requirements-optional"
id="toc-binary-tree-space-requirements-optional"><span
class="toc-section-number">5.8</span> Binary Tree Space Requirements
(optional)</a></li>
<li><a
href="5.9-multiple-binary-trees-optional.html#multiple-binary-trees-optional"
id="toc-multiple-binary-trees-optional"><span
class="toc-section-number">5.9</span> Multiple Binary Trees
(optional)</a></li>
<li><a
href="5.10-a-hard-information-flow-problem-optional.html#a-hard-information-flow-problem-optional"
id="toc-a-hard-information-flow-problem-optional"><span
class="toc-section-number">5.10</span> A Hard Information Flow Problem
(optional)</a></li>
<li><a
href="5.11-binary-tree-chapter-summary.html#binary-tree-chapter-summary"
id="toc-binary-tree-chapter-summary"><span
class="toc-section-number">5.11</span> Binary Tree Chapter
Summary</a></li>
<li><a href="5.12-general-trees-optional.html#general-trees-optional"
id="toc-general-trees-optional"><span
class="toc-section-number">5.12</span> General Trees (optional)</a></li>
<li><a
href="5.13-the-unionfind-algorithm-optional.html#the-unionfind-algorithm-optional"
id="toc-the-unionfind-algorithm-optional"><span
class="toc-section-number">5.13</span> The Union/Find Algorithm
(optional)</a></li>
<li><a
href="5.14-sequential-tree-representations-optional.html#sequential-tree-representations-optional"
id="toc-sequential-tree-representations-optional"><span
class="toc-section-number">5.14</span> Sequential Tree Representations
(optional)</a></li>
</ul></li>
<li><a href="6-binary-search-trees.html#binary-search-trees"
id="toc-binary-search-trees"><span class="toc-section-number">6</span>
Binary Search Trees</a>
<ul>
<li><a
href="6.1-binary-search-tree-definition.html#binary-search-tree-definition"
id="toc-binary-search-tree-definition"><span
class="toc-section-number">6.1</span> Binary Search Tree
Definition</a></li>
<li><a
href="6.2-binary-tree-guided-information-flow.html#binary-tree-guided-information-flow"
id="toc-binary-tree-guided-information-flow"><span
class="toc-section-number">6.2</span> Binary Tree Guided Information
Flow</a></li>
<li><a href="6.3-balanced-trees.html#balanced-trees"
id="toc-balanced-trees"><span class="toc-section-number">6.3</span>
Balanced Trees</a></li>
<li><a href="6.4-the-avl-tree.html#the-avl-tree"
id="toc-the-avl-tree"><span class="toc-section-number">6.4</span> The
AVL Tree</a></li>
<li><a href="6.5-red-black-tree.html#red-black-tree"
id="toc-red-black-tree"><span class="toc-section-number">6.5</span> The
Red-Black Tree (WORK IN PROGRESS)</a></li>
<li><a href="6.6-the-splay-tree-optional.html#the-splay-tree-optional"
id="toc-the-splay-tree-optional"><span
class="toc-section-number">6.6</span> The Splay Tree (optional)</a></li>
<li><a href="6.7-skip-lists-optional.html#skip-lists-optional"
id="toc-skip-lists-optional"><span class="toc-section-number">6.7</span>
Skip Lists (optional)</a></li>
<li><a
href="6.8-binary-search-tree-chapter-summary.html#binary-search-tree-chapter-summary"
id="toc-binary-search-tree-chapter-summary"><span
class="toc-section-number">6.8</span> Binary Search Tree Chapter
Summary</a></li>
</ul></li>
<li><a href="7-priority-queues.html#priority-queues"
id="toc-priority-queues"><span class="toc-section-number">7</span>
Priority queues</a>
<ul>
<li><a
href="7.1-array-implementation-for-complete-binary-trees.html#array-implementation-for-complete-binary-trees"
id="toc-array-implementation-for-complete-binary-trees"><span
class="toc-section-number">7.1</span> Array Implementation for Complete
Binary Trees</a></li>
<li><a
href="7.2-heaps-and-priority-queues.html#heaps-and-priority-queues"
id="toc-heaps-and-priority-queues"><span
class="toc-section-number">7.2</span> Heaps and Priority Queues</a></li>
<li><a href="7.3-heapsort.html#heapsort" id="toc-heapsort"><span
class="toc-section-number">7.3</span> Heapsort</a></li>
<li><a
href="7.4-huffman-coding-trees-optional.html#huffman-coding-trees-optional"
id="toc-huffman-coding-trees-optional"><span
class="toc-section-number">7.4</span> Huffman Coding Trees
(optional)</a></li>
<li><a
href="7.5-priority-queues-chapter-summary.html#priority-queues-chapter-summary"
id="toc-priority-queues-chapter-summary"><span
class="toc-section-number">7.5</span> Priority Queues Chapter
Summary</a></li>
</ul></li>
<li><a href="8-hashing.html#hashing" id="toc-hashing"><span
class="toc-section-number">8</span> Hashing</a>
<ul>
<li><a href="8.1-hash-function-principles.html#hash-function-principles"
id="toc-hash-function-principles"><span
class="toc-section-number">8.1</span> Hash Function Principles</a></li>
<li><a href="8.2-sample-hash-functions.html#sample-hash-functions"
id="toc-sample-hash-functions"><span
class="toc-section-number">8.2</span> Sample Hash Functions</a></li>
<li><a href="8.3-separate-chaining.html#separate-chaining"
id="toc-separate-chaining"><span class="toc-section-number">8.3</span>
Separate Chaining, or Open Hashing</a></li>
<li><a
href="8.4-converting-objects-to-table-indices.html#converting-objects-to-table-indices"
id="toc-converting-objects-to-table-indices"><span
class="toc-section-number">8.4</span> Converting Objects to Table
Indices</a></li>
<li><a href="8.5-bucket-hashing-optional.html#bucket-hashing-optional"
id="toc-bucket-hashing-optional"><span
class="toc-section-number">8.5</span> Bucket Hashing (optional)</a></li>
<li><a href="8.6-open-addressing.html#open-addressing"
id="toc-open-addressing"><span class="toc-section-number">8.6</span>
Open Addressing</a></li>
<li><a
href="8.7-improved-collision-resolution.html#improved-collision-resolution"
id="toc-improved-collision-resolution"><span
class="toc-section-number">8.7</span> Improved Collision
Resolution</a></li>
<li><a
href="8.8-analysis-of-open-addressing.html#analysis-of-open-addressing"
id="toc-analysis-of-open-addressing"><span
class="toc-section-number">8.8</span> Analysis of Open
Addressing</a></li>
<li><a href="8.9-open-addressing-deletion.html#open-addressing-deletion"
id="toc-open-addressing-deletion"><span
class="toc-section-number">8.9</span> Open Addressing, Deletion</a></li>
<li><a
href="8.10-hash-tables-in-real-life-optional.html#hash-tables-in-real-life-optional"
id="toc-hash-tables-in-real-life-optional"><span
class="toc-section-number">8.10</span> Hash Tables in Real Life
(optional)</a></li>
<li><a
href="8.11-hashing-chapter-summary-exercises.html#hashing-chapter-summary-exercises"
id="toc-hashing-chapter-summary-exercises"><span
class="toc-section-number">8.11</span> Hashing Chapter Summary
Exercises</a></li>
</ul></li>
<li><a href="9-graphs-1.html#graphs-1" id="toc-graphs-1"><span
class="toc-section-number">9</span> Graphs</a>
<ul>
<li><a href="9.1-graph-implementations.html#graph-implementations"
id="toc-graph-implementations"><span
class="toc-section-number">9.1</span> Graph Implementations</a></li>
<li><a href="9.2-graph-traversals.html#graph-traversals"
id="toc-graph-traversals"><span class="toc-section-number">9.2</span>
Graph Traversals</a></li>
<li><a href="9.3-topological-sort.html#topological-sort"
id="toc-topological-sort"><span class="toc-section-number">9.3</span>
Topological Sort</a></li>
<li><a href="9.4-shortest-paths-problems.html#shortest-paths-problems"
id="toc-shortest-paths-problems"><span
class="toc-section-number">9.4</span> Shortest-Paths Problems</a></li>
<li><a
href="9.5-minimal-cost-spanning-trees.html#minimal-cost-spanning-trees"
id="toc-minimal-cost-spanning-trees"><span
class="toc-section-number">9.5</span> Minimal Cost Spanning
Trees</a></li>
<li><a
href="9.6-all-pairs-shortest-paths-optional.html#all-pairs-shortest-paths-optional"
id="toc-all-pairs-shortest-paths-optional"><span
class="toc-section-number">9.6</span> All-Pairs Shortest Paths
(optional)</a></li>
<li><a href="9.7-graph-concepts-summary.html#graph-concepts-summary"
id="toc-graph-concepts-summary"><span
class="toc-section-number">9.7</span> Graph Concepts Summary</a></li>
</ul></li>
<li><a href="10-glossary.html#glossary" id="toc-glossary"><span
class="toc-section-number">10</span> Glossary</a></li>
<li><a href="11-bibliography.html#bibliography"
id="toc-bibliography"><span class="toc-section-number">11</span>
Bibliography</a></li>
</ul>
</div></nav></div>
<div class="col-9"><section id="amortized-analysis-optional-work-in-progress"
class="level2" data-number="3.18">
<h2 data-number="3.18"><span class="header-section-number">3.18</span>
Amortized Analysis (optional) (WORK IN PROGRESS)</h2>
<p>This module presents the concept of <a href="10-glossary.html#amortized-analysis" class="term">amortized
analysis</a>, which is the analysis for a series of operations taken
as a whole. In particular, amortized analysis allows us to deal with the
situation where the worst-case cost for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
operations is less than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
times the worst-case cost of any one operation. Rather than focusing on
the individual cost of each operation independently and summing them,
amortized analysis looks at the cost of the entire series and “charges”
each individual operation with a share of the total cost.</p>
<p>We can apply the technique of amortized analysis in the case of a
series of sequential searches in an unsorted array. For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
random searches, the average-case cost for each search is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">n/2</annotation></semantics></math>,
and so the <em>expected</em> total cost for the series is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">n^2/2</annotation></semantics></math>.
Unfortunately, in the worst case all of the searches would be to the
last item in the array. In this case, each search costs
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
for a total worst-case cost of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>n</mi><mn>2</mn></msup><annotation encoding="application/x-tex">n^2</annotation></semantics></math>.
Compare this to the cost for a series of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
searches such that each item in the array is searched for precisely
once. In this situation, some of the searches <em>must</em> be
expensive, but also some searches <em>must</em> be cheap. The total
number of searches, in the best, average, and worst case, for this
problem must be
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>i</mi></mrow><mi>n</mi></msubsup><mi>i</mi><mo>≈</mo><msup><mi>n</mi><mn>2</mn></msup><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\sum_{i=i}^n i \approx n^2/2</annotation></semantics></math>.
This is a factor of two better than the more pessimistic analysis that
charges each operation in the series with its worst-case cost.</p>
<p>As another example of amortized analysis, consider the process of
incrementing a binary counter. The algorithm is to move from the
lower-order (rightmost) bit toward the high-order (leftmost) bit,
changing 1s to 0s until the first 0 is encountered. This 0 is changed to
a 1, and the increment operation is done. Below is an implementation for
the increment operation, assuming that a binary number of length
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
is stored in array <span class="title-ref">A</span> of length
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> i <span class="op">&lt;</span> <span class="bu">len</span>(A) <span class="kw">and</span> A[i] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    A[i] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> i <span class="op">&lt;</span> <span class="bu">len</span>(A):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    A[i] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
<p>If we count from 0 through
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2^n - 1</annotation></semantics></math>,
(requiring a counter with at least
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
bits), what is the average cost for an increment operation in terms of
the number of bits processed? Naive worst-case analysis says that if all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
bits are 1 (except for the high-order bit), then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
bits need to be processed. Thus, if there are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>2</mn><mi>n</mi></msup><annotation encoding="application/x-tex">2^n</annotation></semantics></math>
increments, then the cost is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">n 2^n</annotation></semantics></math>.
However, this is much too high, because it is rare for so many bits to
be processed. In fact, half of the time the low-order bit is 0, and so
only that bit is processed. One quarter of the time, the low-order two
bits are 01, and so only the low-order two bits are processed. Another
way to view this is that the low-order bit is always flipped, the bit to
its left is flipped half the time, the next bit one quarter of the time,
and so on. We can capture this with the summation (charging costs to
bits going from right to left)</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><mfrac><mn>1</mn><msup><mn>2</mn><mi>i</mi></msup></mfrac></mtd><mtd columnalign="center" style="text-align: center"><mo>&lt;</mo></mtd><mtd columnalign="left" style="text-align: left"><mn>2</mn></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{eqnarray}
\sum_{i=0}^{n-1} \frac{1}{2^i} &amp;&lt;&amp; 2
\end{eqnarray}
</annotation></semantics></math></p>
<p>In other words, the average number of bits flipped on each increment
is 2, leading to a total cost of only
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>⋅</mo><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2 \cdot 2^n</annotation></semantics></math>
for a series of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>2</mn><mi>n</mi></msup><annotation encoding="application/x-tex">2^n</annotation></semantics></math>
increments.</p>
<p>A useful concept for amortized analysis is illustrated by a simple
variation on the stack data structure, where the <span
class="title-ref">pop</span> function is slightly modified to take a
second parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
indicating that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
pop operations are to be performed.</p>
<p>The “local” worst-case analysis for <span
class="title-ref">multipop</span> is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Theta(n)</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
elements in the stack. Thus, if there are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mn>1</mn></msub><annotation encoding="application/x-tex">m_1</annotation></semantics></math>
calls to <span class="title-ref">push</span> and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mn>2</mn></msub><annotation encoding="application/x-tex">m_2</annotation></semantics></math>
calls to <span class="title-ref">multipop</span>, then the naive
worst-case cost for the series of operation is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mn>1</mn></msub><mo>+</mo><msub><mi>m</mi><mn>2</mn></msub><mo>⋅</mo><mi>n</mi><mo>=</mo><msub><mi>m</mi><mn>1</mn></msub><mo>+</mo><msub><mi>m</mi><mn>2</mn></msub><mo>⋅</mo><msub><mi>m</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">m_1 + m_2\cdot n = m_1 + m_2 \cdot m_1</annotation></semantics></math>.
This analysis is unreasonably pessimistic. Clearly it is not really
possible to pop
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mn>1</mn></msub><annotation encoding="application/x-tex">m_1</annotation></semantics></math>
elements each time <span class="title-ref">multipop</span> is called.
Analysis that focuses on single operations cannot deal with this global
limit, and so we turn to amortized analysis to model the entire series
of operations.</p>
<p>The key to an amortized analysis of this problem lies in the concept
of <a href="10-glossary.html#potential" class="term">potential</a>. At any given time, a certain
number of items may be on the stack. The cost for <span
class="title-ref">multipop</span> can be no more than this number of
items. Each call to <span class="title-ref">push</span> places another
item on the stack, which can be removed by only a single <span
class="title-ref">multipop</span> operation. Thus, each call to <span
class="title-ref">push</span> raises the potential of the stack by one
item. The sum of costs for all calls to <span
class="title-ref">multipop</span> can never be more than the total
potential of the stack (aside from a constant time cost associated with
each call to <span class="title-ref">multipop</span> itself).</p>
<p>The amortized cost for any series of <span
class="title-ref">push</span> and <span
class="title-ref">multipop</span> operations is the sum of three costs.
First, each of the <span class="title-ref">push</span> operations takes
constant time. Second, each <span class="title-ref">multipop</span>
operation takes a constant time in overhead, regardless of the number of
items popped on that call. Finally, we count the sum of the potentials
expended by all <span class="title-ref">multipop</span> operations,
which is at most
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mn>1</mn></msub><annotation encoding="application/x-tex">m_1</annotation></semantics></math>,
the number of <span class="title-ref">push</span> operations. This total
cost can therefore be expressed as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>m</mi><mn>1</mn></msub><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>m</mi><mn>2</mn></msub><mo>+</mo><msub><mi>m</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="center" style="text-align: center"><mo>=</mo></mtd><mtd columnalign="left" style="text-align: left"><mi>Θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>m</mi><mn>1</mn></msub><mo>+</mo><msub><mi>m</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{eqnarray}
m_1 + (m_2 + m_1) &amp;=&amp; \Theta(m_1 + m_2)
\end{eqnarray}
</annotation></semantics></math></p>
<p>A similar argument was used in our analysis for the partition
function in the <a href="2.11-quicksort.html#quicksort">Quicksort</a>
algorithm. While on any given pass through the while loop the left or
right pointers might move all the way through the remainder of the
partition, doing so would reduce the number of times that the while loop
can be further executed.</p>
<p>Our final example uses amortized analysis to prove a relationship
between the cost of the <a href="10-glossary.html#move-to-front" class="term">move-to-front</a>
self-organizing list heuristic and the cost for the optimal static
ordering of the list.</p>
<p>Recall that, for a series of search operations, the minimum cost for
a static list results when the list is sorted by frequency of access to
its records. This is the optimal ordering for the records if we never
allow the positions of records to change, because the most-frequently
accessed record is first (and thus has least cost), followed by the next
most frequently accessed record, and so on.</p>
<div id="MTFThm">
<div class="col-9"><section id="theorem-1" class="level4 unnumbered topic">
<h4 class="unnumbered">Theorem</h4>
<p><strong>Theorem:</strong> The total number of comparisons required by
any series
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
or more searches on a self-organizing list of length
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
using the move-to-front heuristic is never more than twice the total
number of comparisons required when series
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
is applied to the list stored in its optimal static order.</p>
<p><strong>Proof:</strong> Each comparison of the search key with a
record in the list is either successful or unsuccessful. For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
searches, there must be exactly
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
successful comparisons for both the self-organizing list and the static
list. The total number of unsuccessful comparisons in the
self-organizing list is the sum, over all pairs of distinct keys, of the
number of unsuccessful comparisons made between that pair.</p>
<p>Consider a particular pair of keys:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.
For any sequence of searches
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>,
the total number of (unsuccessful) comparisons between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
is identical to the number of comparisons between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
required for the subsequence of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
made up only of searches for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.
Call this subsequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mrow><mi>A</mi><mi>B</mi></mrow></msub><annotation encoding="application/x-tex">S_{AB}</annotation></semantics></math>.
In other words, including searches for other keys does not affect the
relative position of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
and so does not affect the relative contribution to the total cost of
the unsuccessful comparisons between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.</p>
<p>The number of unsuccessful comparisons between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
made by the move-to-front heuristic on subsequence
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mrow><mi>A</mi><mi>B</mi></mrow></msub><annotation encoding="application/x-tex">S_{AB}</annotation></semantics></math>
is at most twice the number of unsuccessful comparisons between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
required when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mrow><mi>A</mi><mi>B</mi></mrow></msub><annotation encoding="application/x-tex">S_{AB}</annotation></semantics></math>
is applied to the optimal static ordering for the list. To see this,
assume that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mrow><mi>A</mi><mi>B</mi></mrow></msub><annotation encoding="application/x-tex">S_{AB}</annotation></semantics></math>
contains
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
s and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
s, with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>≤</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i \leq j</annotation></semantics></math>.
Under the optimal static ordering,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
unsuccessful comparisons are required because
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
must appear before
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
in the list (because its access frequency is higher). Move-to-front will
yield an unsuccessful comparison whenever the request sequence changes
from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
or from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>.
The total number of such changes possible is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>i</mi></mrow><annotation encoding="application/x-tex">2i</annotation></semantics></math>
because each change involves an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
and each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
can be part of at most two changes.</p>
<p>Because the total number of unsuccessful comparisons required by
move-to-front for any given pair of keys is at most twice that required
by the optimal static ordering, the total number of unsuccessful
comparisons required by move-to-front for all pairs of keys is also at
most twice as high. Because the number of successful comparisons is the
same for both methods, the total number of comparisons required by
move-to-front is less than twice the number of comparisons required by
the optimal static ordering.</p>
</section></div>
</div>
</section>
</div></body>
</html>
