<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-GB" xml:lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Cliff Shaffer" />
  <meta name="author" content="Peter Ljunglöf" />
  <meta name="author" content="Nick Smallbone" />
  <title>DSABook – Sorting</title>
  <link rel="stylesheet" href="../css/main.css" />
  <link rel="stylesheet" href="../css/book.css" />
  <link rel="stylesheet" href="../css/code.css" />
  <link rel="stylesheet" href="../css/math.css" />
  <link rel="stylesheet" href="../css/quiz.css" />
  <link rel="stylesheet" href="../css/mobile.css" />
  <link rel="stylesheet" href="../css/print.css" />
  
  <link rel="stylesheet" href="../lib/JSAV.css" type="text/css" />
  <link rel="stylesheet" href="../lib/odsaMOD.css" type="text/css" />
  <link rel="stylesheet" href="../lib/jquery.ui.min.css" type="text/css" />
  <link rel="stylesheet" href="../lib/odsaStyle.css" type="text/css" />

  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:    './',
      VERSION:     '0.4.1',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  <script type="text/javascript" src="../lib/jquery.min.js"></script>
  <script type="text/javascript" src="../lib/jquery.migrate.min.js"></script>
  <script type="text/javascript" src="../lib/localforage.min.js"></script>
  <script type="text/javascript" src="../lib/accessibility.js"></script>
  <script type="text/javascript" src="../lib/jquery.ui.min.js"></script>
  <script type="text/javascript" src="../lib/jquery.transit.js"></script>
  <script type="text/javascript" src="../lib/raphael.js"></script>
  <script type="text/javascript" src="../lib/JSAV.js"></script>
  <script type="text/javascript" src="../lib/config.js"></script>
  <script type="text/javascript" src="../lib/timeme.js"></script>
  <script type="text/javascript" src="../lib/odsaUtils.js"></script>
  <script type="text/javascript" src="../lib/odsaMOD.js"></script>
  <script type="text/javascript" src="../lib/d3.min.js"></script>
  <script type="text/javascript" src="../lib/d3-selection-multi.v1.min.js"></script>
  <script type="text/javascript" src="../lib/dataStructures.js"></script>
  <script type="text/javascript" src="../lib/conceptMap.js"></script>

  <script>
    ODSA.SETTINGS.MODULE_SECTIONS = [
    'internal-variables', 
    'getting-and-setting-values', 
    'adding-elements', 
    'add-practice-exericse', 
    'removing-elements', 
    'remove-practice-exericise', 
    'static-array-based-list-summary-questions', 
    'static-array-based-list:-full-code',
    ];
    ODSA.SETTINGS.MODULE_NAME = "DSABook";
    ODSA.SETTINGS.MODULE_LONG_NAME = "Data Structures and Algorithms";
    JSAV_OPTIONS['lang']='en';
    JSAV_EXERCISE_OPTIONS['code']='pseudo';
  </script>

  
  <script type="text/javascript" src="../scripts/quizhandler.js"></script>
</head>

<body>

<header>
<nav class="sitenav">
<div></div>
<h1><a href="index.html" class="navbutton" accesskey="t" rel="top">Data Structures and Algorithms</a></h1>
<div></div>
</nav>
<nav class="sitenav">
<div>
<a href="2.1-searching-in-an-array.html" class="navbutton">&lt;&lt;</a>
<a href="2.1-searching-in-an-array.html" accesskey="p" rel="previous">Searching in an Array</a>
</div>
<div>
<a href="2.3-sorting-terminology-and-notation.html" accesskey="n" rel="next">Sorting Terminology and Notation</a>
<a href="2.3-sorting-terminology-and-notation.html" class="navbutton">&gt;&gt;</a>
</div>
</nav>
</header>

<main>
<section id="sorting" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span>
Sorting</h2>
<p>We have seen that, when an array is sorted in ascending order,
<em>binary search</em> can be used to find items in it efficiently. But
what about when we have a collection of data that is not in any order?
If we will often need to search for items in the data, it makes sense to
<em>sort the data</em> first. In this chapter we will study algorithms
for sorting arrays in ascending order.</p>
<p>We sort many things in our everyday lives: A handful of cards when
playing Bridge; bills and other piles of paper; jars of spices; and so
on. And we have many intuitive strategies that we can use to do the
sorting, depending on how many objects we have to sort and how hard they
are to move around. Sorting is also one of the most frequently performed
computing tasks. We might sort the records in a database so that we can
search the collection efficiently. We might sort customer records by zip
code so that when we print an advertisement we can then mail them more
cheaply. We might use sorting to help an algorithm to solve some other
problem. For example, <a
href="9.6-minimal-cost-spanning-trees.html#kruskals-algorithm"
class="term"
title="An algorithm for computing the MCST of a graph. During processing, it makes use of the UNION/FIND process to efficiently determine of two vertices are within the same subgraph.">Kruskal’s
algorithm</a> to find <a
href="9.6-minimal-cost-spanning-trees.html#minimal-cost-spanning-trees"
class="term" title="">minimal-cost spanning trees</a> must sort the
edges of a graph by their lengths before it can process them.</p>
<p>Because sorting is so important, naturally it has been studied
intensively and many algorithms have been devised. Some of these
algorithms are straightforward adaptations of schemes we use in everyday
life. For example, a natural way to sort your cards in a bridge hand is
to go from left to right, and place each card in turn in its correct
position relative to the other cards that you have already sorted. This
is the idea behind <a href="2.4-insertion-sort.html#insertion-sort"
class="term"
title="A sorting algorithm with $\Theta(n^2)$ average and worst case cost, and $Theta(n)$ best case cost. This best case cost makes it useful when we have reason to expect the input to be nearly sorted.">Insertion
Sort</a>. Other sorting algorithms are totally alien to how humans do
things, having been invented to sort thousands or even millions of
records stored on the computer. For example, no normal person would use
<a href="2.11-quicksort.html#quicksort" class="term"
title="A sort that is $\Theta(n \log n)$ in the best and average cases, though $\Theta(n^2)$ in the worst case. However, a reasonable implmentation will make the worst case occur under exceedingly rare circumstances. Due to its tight inner loop, it tends to run better than any other known sort in general cases. Thus, it is a popular sort to use in code libraries. It works by divide and conquer, by selecting a pivot value, splitting the list into parts that are either less than or greater than the pivot, and then sorting the two parts.">Quicksort</a>
to order a pile of bills by date, even though Quicksort is one of the
standard sorting algorithms of choice for most software libraries. After
years of study, there are still unsolved problems related to sorting.
New algorithms are still being developed and refined for special-purpose
applications.</p>
<p>Along with introducing this central problem in computer science,
studying sorting algorithms helps us to understand issues in algorithm
design and analysis. For example, the sorting algorithms in this chapter
show multiple approaches to using <a
href="10-glossary.html#divide-and-conquer" class="term"
title="A technique for designing algorithms where a solution is found by breaking the problem into smaller (similar) subproblems, solving the subproblems, then combining the subproblem solutions to form the solution to the original problem. This process is often implemented using recursion.">divide
and conquer</a>. In particular, there are multiple ways to do the
dividing. <a href="2.9-mergesort.html#mergesort" class="term"
title="A sorting algorithm that requires $\Theta(n \log n)$ in the best, average, and worst cases. Conceptually it is simple: Split the list in half, sort the halves, then merge them together. It is a bit complicated to implement efficiently on an array.">Mergesort</a>
divides a list in half. <a href="2.11-quicksort.html#quicksort"
class="term"
title="A sort that is $\Theta(n \log n)$ in the best and average cases, though $\Theta(n^2)$ in the worst case. However, a reasonable implmentation will make the worst case occur under exceedingly rare circumstances. Due to its tight inner loop, it tends to run better than any other known sort in general cases. Thus, it is a popular sort to use in code libraries. It works by divide and conquer, by selecting a pivot value, splitting the list into parts that are either less than or greater than the pivot, and then sorting the two parts.">Quicksort</a>
divides a list into big values and small values. <a
href="10-glossary.html#radix-sort" class="term"
title="A sorting algorithm that works by processing records with $k$ digit keys in $k$ passes, where each pass sorts the records according to the current digit. At the end of the process, the records will be sorted. This can be efficient if the number of digits is small compared to the number of records. However, if the $n$ records all have unique key values, than at least $\Omega(\log n)$ digits are required, leading to an $\Omega(n \log n)$ sorting algorithm that tends to be much slower than other sorting algorithms like Quicksort or mergesort.">Radix
Sort</a> divides the problem by working on one digit of the key at a
time.</p>
<p>Sorting algorithms can also illustrate a wide variety of algorithm
analysis techniques. Quicksort illustrates that it is possible for an
algorithm to have an <a href="10-glossary.html#average-case"
class="term"
title="In algorithm analysis, specifically complexity of an algorithm, the average of the costs for all problem instances of a given input size $n$. If not all problem instances have equal probability of occurring, then the average case must be calculated using a weighted average that is specified with the problem (for example, every input may be equally likely). Every input size $n$ has its own average case. We **never** consider the average case as removed from input size.">average
case</a> whose growth rate is significantly smaller than its <a
href="10-glossary.html#worst-case" class="term"
title="In algorithm analysis, specifically complexity of an algorithm, the problem instance from among all problem instances for a given input size $n$ that has the greatest cost. Every input size $n$ has its own worst case. We **never** consider the worst case as removed from input size.">worst
case</a>. It is possible to speed up one sorting algorithm (such as <a
href="10-glossary.html#shellsort" class="term"
title="A sort that relies on the best-case cost of insertion sort to improve over $\Theta(n^2)$ worst case cost.">Shellsort</a>
or <a href="2.11-quicksort.html#quicksort" class="term"
title="A sort that is $\Theta(n \log n)$ in the best and average cases, though $\Theta(n^2)$ in the worst case. However, a reasonable implmentation will make the worst case occur under exceedingly rare circumstances. Due to its tight inner loop, it tends to run better than any other known sort in general cases. Thus, it is a popular sort to use in code libraries. It works by divide and conquer, by selecting a pivot value, splitting the list into parts that are either less than or greater than the pivot, and then sorting the two parts.">Quicksort</a>)
by taking advantage of the <a href="10-glossary.html#best-case"
class="term"
title="In algorithm analysis, specifically complexity of an algorithm, the problem instance from among all problem instances for a given input size $n$ that has least cost. Every input size $n$ has its own best case. We **never** consider the best case as removed from input size.">best
case</a> behavior of another algorithm (Insertion Sort). Special case
behavior by some sorting algorithms makes them a good solution for
special niche applications (<a href="7.3-heapsort.html#heapsort"
class="term"
title="A sorting algorithm that costs $\Theta(n \log n)$ time in the best, average, and worst cases. It tends to be slower than Mergesort and Quicksort. It works by building a max heap, and then repeatedly removing the item with maximum key value (moving it to the end of the heap) until all elements have been removed (and replaced at their proper location in the array).">Heapsort</a>).
Sorting provides an example of an important technique for analyzing the
lower bound for a problem.</p>
<p>This chapter covers several standard algorithms appropriate for
sorting a collection of records that fit into the computer’s main
memory. It begins with a discussion of three simple, but relatively
slow, algorithms that require <a
href="10-glossary.html#quadratic-growth-rate" class="term"
title="A growth rate function of the form $cn^2$ where $n$ is the input size and $c$ is a constant.">quadratic</a>
time in the size of the array. Three algorithms with considerably better
performance are then presented, some with <a
href="10-glossary.html#linearithmic-growth-rate" class="term"
title="For input size $n$, a growth rate of $cn \log n$ (for $c$ any positive constant). In other words, the cost of the associated function is slightly larger than linear on the input size.">linearithmic</a>
worst-case running time. The chapter concludes with a proof that you
cannot implement a generic sorting algorithm with better worst-case
behaviour than <a href="10-glossary.html#linearithmic-growth-rate"
class="term"
title="For input size $n$, a growth rate of $cn \log n$ (for $c$ any positive constant). In other words, the cost of the associated function is slightly larger than linear on the input size.">linearithmic</a>
time.</p>
</section>
</main>

<footer>
<nav class="sitenav">
<div class="navlink">
<a href="2.1-searching-in-an-array.html" class="navbutton">&lt;&lt;</a>
<a href="2.1-searching-in-an-array.html" accesskey="p" rel="previous">Searching in an Array</a>
</div>
<div class="navlink">
<a href="2.3-sorting-terminology-and-notation.html" accesskey="n" rel="next">Sorting Terminology and Notation</a>
<a href="2.3-sorting-terminology-and-notation.html" class="navbutton">&gt;&gt;</a>
</div>
</nav>
</footer>

</body>
</html>

