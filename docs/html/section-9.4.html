<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-GB" xml:lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Peter Ljungl√∂f" />
  <meta name="author" content="Alex Gerdes" />
  <meta name="author" content="(editors)" />
  <title>DSABook ‚Äì Case study: Huffman coding</title>
  <link rel="stylesheet" href="../css/main.css" />
  <link rel="stylesheet" href="../css/book.css" />
  <link rel="stylesheet" href="../css/code.css" />
  <link rel="stylesheet" href="../css/math.css" />
  <link rel="stylesheet" href="../css/quiz.css" />
  <link rel="stylesheet" href="../css/mobile.css" />
  <link rel="stylesheet" href="../css/print.css" />
  <style id="dynamicStyleSheet"></style>
  
  <link rel="stylesheet" href="../lib/JSAV.css" type="text/css" />
  <link rel="stylesheet" href="../lib/odsaMOD.css" type="text/css" />
  <link rel="stylesheet" href="../lib/jquery.ui.min.css" type="text/css" />
  <link rel="stylesheet" href="../lib/odsaStyle.css" type="text/css" />

  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:    './',
      VERSION:     '0.4.1',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  <script type="text/javascript" src="../lib/jquery.min.js"></script>
  <script type="text/javascript" src="../lib/jquery.migrate.min.js"></script>
  <script type="text/javascript" src="../lib/localforage.min.js"></script>
  <script type="text/javascript" src="../lib/accessibility.js"></script>
  <script type="text/javascript" src="../lib/jquery.ui.min.js"></script>
  <script type="text/javascript" src="../lib/jquery.transit.js"></script>
  <script type="text/javascript" src="../lib/raphael.js"></script>
  <script type="text/javascript" src="../lib/JSAV.js"></script>
  <script type="text/javascript" src="../lib/config.js"></script>
  <script type="text/javascript" src="../lib/timeme.js"></script>
  <script type="text/javascript" src="../lib/odsaUtils.js"></script>
  <script type="text/javascript" src="../lib/odsaMOD.js"></script>
  <script type="text/javascript" src="../lib/d3.min.js"></script>
  <script type="text/javascript" src="../lib/d3-selection-multi.v1.min.js"></script>
  <script type="text/javascript" src="../lib/dataStructures.js"></script>
  <script type="text/javascript" src="../lib/conceptMap.js"></script>

  <script>
    ODSA.SETTINGS.MODULE_SECTIONS = [
    'internal-variables', 
    'getting-and-setting-values', 
    'adding-elements', 
    'add-practice-exericse', 
    'removing-elements', 
    'remove-practice-exericise', 
    'static-array-based-list-summary-questions', 
    'static-array-based-list:-full-code',
    ];
    ODSA.SETTINGS.MODULE_NAME = "DSABook";
    ODSA.SETTINGS.MODULE_LONG_NAME = "Data Structures and Algorithms";
    JSAV_OPTIONS['lang']='en';
    JSAV_EXERCISE_OPTIONS['code']='pseudo';
  </script>

  
  <script type="text/javascript" src="../scripts/quizhandler.js"></script>
<link href="../interactive/Binary/HuffProofCON.css" rel="stylesheet" type="text/css"/>
<link href="../interactive/Binary/huffmanCON.css" rel="stylesheet" type="text/css"/>
<link href="../interactive/DataStructures/huffman.css" rel="stylesheet" type="text/css"/></head>

<body>

<header>
<nav class="sitenav">
<div></div>
<h1><a href="index.html" class="navbutton" accesskey="t" rel="top">Data Structures and Algorithms</a></h1>
<div></div>
</nav>
<nav class="sitenav">
<div>
<a href="section-9.3.html" class="navbutton">&lt;&lt;</a>
<a href="section-9.3.html" accesskey="p" rel="previous">Case study: Heapsort</a>
</div>
<div>
<a href="section-9.5.html" accesskey="n" rel="next">Review questions</a>
<a href="section-9.5.html" class="navbutton">&gt;&gt;</a>
</div>
</nav>
</header>

<main>
<section id="sec:case-study-huffman-coding" class="level2"
data-number="9.4">
<h2 data-number="9.4"><span class="header-section-number">9.4</span>
Case study: Huffman coding</h2>
<p>One can often gain an improvement in space requirements in exchange
for a penalty in running time. There are many situations where this is a
desirable tradeoff. A typical example is storing files on disk. If the
files are not actively used, the owner might wish to compress them to
save space. Later, they can be uncompressed for use, which costs some
time, but only once.</p>
<p>We often represent a set of items in a computer program by assigning
a unique code to each item. For example, the standard Latin-1 scheme
(the formal name is ISO 8859-1) assigns a unique eight-bit value to each
character. It takes a certain minimum number of bits to provide enough
unique codes so that we have a different one for each character. For
example, it takes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">‚åà</mo><mi>log</mi><mspace width="0.222em"></mspace><mn>256</mn><mo stretchy="true" form="postfix">‚åâ</mo></mrow><annotation encoding="application/x-tex">\left\lceil \log\ 256\right\rceil</annotation></semantics></math>
or eight bits to provide the 256 unique codes needed to represent the
256 symbols of the Latin-1 character set.</p>
<div class="online">
<p>The requirement for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">‚åà</mo><mi>log</mi><mspace width="0.222em"></mspace><mi>n</mi><mo stretchy="true" form="postfix">‚åâ</mo></mrow><annotation encoding="application/x-tex">\left \lceil \log\ n \right\rceil</annotation></semantics></math>
bits to represent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
unique code values assumes that all codes will be the same length, as
are Latin-1 codes. These are called <a
href="section-14.html#fixed-length-coding" class="term"
title="Given a collection of objects, a fixed-length coding scheme assigns a code to each object in the collection using codes that are all of the same length. Standard ASCII and Unicode representations for characters are both examples of fixed-length coding schemes. This is in contrast to variable-length coding.">fixed-length
codes</a>. If all characters were used equally often, then a
fixed-length coding scheme is the most space efficient method. However,
you are probably aware that not all characters are used equally often in
many applications. For example, the various letters in an English
language document have greatly different frequencies of use.</p>
<p><a href="section-9.4.html#tbl:relative-frequencies">Table¬†9.1</a>
below shows the relative frequencies of the letters of the alphabet.
From this table we can see that the letter ‚ÄòE‚Äô appears about 60 times
more often than the letter ‚ÄòZ‚Äô. In normal Latin-1, the words ‚ÄúDEED‚Äù and
‚ÄúMUCK‚Äù require the same amount of space (four bytes). It would seem that
words such as ‚ÄúDEED‚Äù, which are composed of relatively common letters,
should be storable in less space than words such as ‚ÄúMUCK‚Äù, which are
composed of relatively uncommon letters.</p>
<div id="tbl:relative-frequencies">
<table>
<caption>Table 9.1: Relative frequencies for the 26 letters of the
alphabet as they appear in a selected set of English documents.
‚ÄúFrequency‚Äù represents the expected frequency of occurrence per 1000
letters, ignoring case</caption>
<thead>
<tr>
<th style="text-align: center;">Letter</th>
<th style="text-align: center;">Frequency</th>
<th style="text-align: center;">Letter</th>
<th style="text-align: center;">Frequency</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">A</td>
<td style="text-align: center;">77</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">67</td>
</tr>
<tr>
<td style="text-align: center;">B</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">67</td>
</tr>
<tr>
<td style="text-align: center;">C</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">P</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: center;">D</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">Q</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">E</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">R</td>
<td style="text-align: center;">59</td>
</tr>
<tr>
<td style="text-align: center;">F</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">S</td>
<td style="text-align: center;">67</td>
</tr>
<tr>
<td style="text-align: center;">G</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">85</td>
</tr>
<tr>
<td style="text-align: center;">H</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">U</td>
<td style="text-align: center;">37</td>
</tr>
<tr>
<td style="text-align: center;">I</td>
<td style="text-align: center;">76</td>
<td style="text-align: center;">V</td>
<td style="text-align: center;">12</td>
</tr>
<tr>
<td style="text-align: center;">J</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">W</td>
<td style="text-align: center;">22</td>
</tr>
<tr>
<td style="text-align: center;">K</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: center;">L</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">22</td>
</tr>
<tr>
<td style="text-align: center;">M</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">Z</td>
<td style="text-align: center;">2</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>If some letters are used more frequently than others, is it possible
to take advantage of this fact and somehow assign them shorter codes?
The price could be that other letters require longer codes, but this
might be worthwhile if such letters appear rarely enough. This concept
is at the heart of file compression techniques in common use today. In
this section we present one such approach to assigning <a
href="section-14.html#variable-length-coding" class="term"
title="Given a collection of objects, a variable-length coding scheme assigns a code to each object in the collection using codes that can be of different lengths. Typically this is done in a way such that the objects that are most likely to be used have the shortest codes, with the goal of minimising the total space needed to represent a sequence of objects, such as when representing the characters in a document. Huffman coding is an example of a variable-length coding scheme. This is in contrast to fixed-length coding.">variable-length
codes</a>, called <a href="section-14.html#huffman-codes" class="term"
title="The codes given to a collection of letters (or other symbols) through the process of Huffman coding. Huffman coding uses a Huffman coding tree to generate the codes. The codes can be of variable length, such that the letters which are expected to appear most frequently are shorter. Huffman coding is optimal whenever the true frequencies are known, and the frequency of a letter is independent of the context of that letter in the message.">Huffman
coding</a>.</p>
<div class="online">
<p>While it is not commonly used in its simplest form for file
compression (there are better methods), Huffman coding gives the flavor
of such coding schemes. One motivation for studying Huffman coding is
because it provides our first opportunity to see a type of tree
structure referred to as a <a href="section-14.html#search-trie"
class="term" title="Any search tree that is a trie.">search
trie</a>.</p>
<p>To keep things simple, the following examples for building Huffman
trees uses a <a href="section-14.html#sorted-list" class="term"
title="A list where the records stored in the list are arranged so that their key values are in ascending order. If the list uses an array-based list implementation, then it can use binary search for a cost of $O(\log n)$. But both insertion and deletion will be require $O(n)$ time.">sorted
list</a> to keep the partial Huffman trees ordered by frequency. But a
real implementation would use a <a href="section-14.html#priority-queue"
class="term"
title="An ADT whose primary operations of insert of records, and deletion of the greatest (or, in an alternative implementation, the least) valued record. Most often implemented using the heap data structure. The name comes from a common application where the records being stored represent tasks, with the ordering values based on the priorities of the tasks.">priority
queue</a> keyed by the frequencies.</p>
<section id="sec:huffman-coding-trees" class="level3"
data-number="9.4.1">
<h3 data-number="9.4.1"><span class="header-section-number">9.4.1</span>
Huffman coding trees</h3>
<p>Huffman coding assigns codes to letters such that the length of the
code depends on the relative frequency or <a
href="section-14.html#weight" class="term"
title="A cost or distance most often associated with an edge in a graph.">weight</a>
of the corresponding letter. Thus, it is a variable-length code. If the
estimated frequencies for letters match the actual frequency found in an
encoded message, then the length of that message will typically be less
than if a fixed-length code had been used. The Huffman code for each
letter is derived from a full binary tree called the <a
href="section-14.html#huffman-tree" class="term"
title="Shorter form of the term Huffman coding tree.">Huffman tree</a>.
Each leaf of the Huffman tree corresponds to a letter, and we define the
weight of the leaf node to be the weight (frequency) of its associated
letter.</p>
<p>Here is a possible implementation of Huffman trees, where the type
<code>T</code> can e.g.¬†be letters:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode pseudo"><code class="sourceCode pseudo"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">datatype</span> HuffmanTree <span class="kw">of</span> T:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    weight: <span class="bu">Int</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    elem: T</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    left: HuffmanTree</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    right: HuffmanTree</span></code></pre></div>
<p>Note that this is not the only possible implementation. As mentioned
above, Huffman trees are <em>complete</em>, meaning that every node
either has two children or none. And, it‚Äôs only nodes without children
(i.e., leaves) that have an associated element. So, an alternative
implementation would be to divide nodes into internal nodes and
leaves.</p>
</section>
<section id="sec:building-huffman-trees" class="level3"
data-number="9.4.2">
<h3 data-number="9.4.2"><span class="header-section-number">9.4.2</span>
Building Huffman trees</h3>
<p>The goal of Huffman coding is to build a tree with the <a
href="section-14.html#minimum-external-path-weight" class="term"
title="Given a collection of objects, each associated with a leaf node in a tree, the binary tree with minimum external path weight is the one with the minimum sum of weighted path lengths for the given set of leaves. This concept is used to create a Huffman coding tree, where a letter with high weight should have low depth, so that it will count the least against the total path length. As a result, another letter might be pushed deeper in the tree if it has less weight.">minimum
external path weight</a>. Define the <a
href="section-14.html#weighted-path-length" class="term"
title="Given a tree, and given a weight for each leaf in the tree, the weighted path length for a leaf is its weight times its depth.">weighted
path length</a> of a leaf to be its weight times its depth. The binary
tree with minimum external path weight is the one with the minimum sum
of weighted path lengths for the given set of leaves. A letter with high
weight should have low depth, so that it will count the least against
the total path length. As a result, another letter might be pushed
deeper in the tree if it has less weight.</p>
<p>The process of building the Huffman tree for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
letters is quite simple.</p>
<ul>
<li><p>First, create a collection of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
initial Huffman trees, each of which is a single leaf node containing
one of the letters. Put the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
partial trees onto a <em>minimum</em> priority queue organised by weight
(frequency).</p></li>
<li><p>Next, remove the first two trees (the ones with lowest weight)
from the priority queue.</p>
<ul>
<li>Join these two trees together to create a new tree whose root has
the two trees as children, and whose weight is the sum of the weights of
the two trees.</li>
<li>Put this new tree back into the priority queue.</li>
</ul></li>
<li><p>Repeat this process until all of the partial Huffman trees have
been combined into one.</p></li>
</ul>
<div class="online">
<section id="sec:example-constructing-a-huffman-tree"
class="level4 unnumbered example">
<h4 class="unnumbered">Example: Constructing a Huffman tree</h4>
<p>Assume the following relative frequencies for eight selected
letters:</p>
<table>
<tbody>
<tr>
<td style="text-align: left;"><strong>Letter</strong></td>
<td style="text-align: center;">C</td>
<td style="text-align: center;">D</td>
<td style="text-align: center;">E</td>
<td style="text-align: center;">K</td>
<td style="text-align: center;">L</td>
<td style="text-align: center;">M</td>
<td style="text-align: center;">U</td>
<td style="text-align: center;">Z</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Frequency</strong></td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">2</td>
</tr>
</tbody>
</table>
<p>Here is a slideshow that illustrates the Huffman tree construction
process for these letters.</p>

<div id="huffmanBuildCON" class="ssAV" data-short-name="huffmanBuildCON" data-long-name="Huffman Coding Tree Slideshow: Build" alt="Huffman Coding Tree Slideshow: Build" tabIndex="-1">
<span class="jsavcounter"></span>
<div class="jsavcontrols"></div>
<p class="jsavoutput jsavline"></p>
<div class="jsavcanvas"></div>
</div>


<script type="text/javascript" src="../interactive/DataStructures/huffman.js"></script>
<script type="text/javascript" src="../interactive/Binary/huffmanBuildCON.js"></script>
<script>
  $(document).ready(function(){
    function NewAV() {return new JSAV("huffmanBuildCON", {animationMode: "none"})}
    function AddCSS(rule) {document.getElementById("dynamicStyleSheet").sheet.insertRule("#huffmanBuildCON "+rule)}
    
  });
</script>

</section>
</div>
<p>Here is pseudocode for the tree-building process. It takes a list of
characters paired with their frequencies, and returns the final Huffman
tree:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode pseudo"><code class="sourceCode pseudo"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> buildHuffmanTree(frequencies):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Initialise a min-heap with Huffman leaves.</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    huffmanHeap <span class="op">=</span> <span class="kw">new</span> MinHeap()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="kw">each</span> pair (char, freq) <span class="kw">in</span> frequencies:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        huffmanHeap.<span class="bu">add</span>(<span class="kw">new</span> HuffmanTree(freq, char, <span class="va">null</span>, <span class="va">null</span>))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Iterate until there is only one tree left on the heap.</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> huffmanHeap.<span class="bu">size</span> <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Remove the two minimum trees from the heap.</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        t1 <span class="op">=</span> huffmanHeap.<span class="bu">removeMin</span>()</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        t2 <span class="op">=</span> huffmanHeap.<span class="bu">removeMin</span>()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> t1.weight <span class="op">+</span> t2.weight</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Combine the trees and add the new tree to the heap.</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        t3 <span class="op">=</span> <span class="kw">new</span> HuffmanTree(weight, <span class="va">null</span>, t1, t2)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        huffmanHeap.<span class="bu">add</span>(t3)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Return the final Huffman tree.</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> huffmanHeap.<span class="bu">removeMin</span>()</span></code></pre></div>
<p>The function first initialises a min-heap of Huffman trees, creating
one singleton Huffman leaf from each character.</p>
<p>The main body of <code>buildHuffmanTree</code> consists of a while
loop that does the following: It takes the first two trees off the heap,
and creates a new tree by making them subtrees. The weight of the new
tree is the sum of the two children trees. Finally, it adds the new tree
to the min-heap.</p>
</section>
<section id="sec:assigning-and-using-huffman-codes" class="level3"
data-number="9.4.3">
<h3 data-number="9.4.3"><span class="header-section-number">9.4.3</span>
Assigning and using Huffman codes</h3>
<p>Once the Huffman tree has been constructed, it is an easy matter to
assign bit codes to individual characters. Beginning at the root, we
assign either a ‚Äò0‚Äô or a ‚Äò1‚Äô to each edge in the tree. ‚Äò0‚Äô is assigned
to edges connecting a node with its left child, and ‚Äò1‚Äô to edges
connecting a node with its right child.</p>
<div class="dsvis">
<details open="true">
<summary>
<p>This process is illustrated by the following slideshow, for our
8-letter example above.</p>
</summary>

<div id="huffmanLabelCON" class="ssAV" data-short-name="huffmanLabelCON" data-long-name="Huffman Coding Tree Slideshow: Label Edges" alt="Huffman Coding Tree Slideshow: Label Edges" tabIndex="-1">
<span class="jsavcounter"></span>
<div class="jsavcontrols"></div>
<p class="jsavoutput jsavline"></p>
<div class="jsavcanvas"></div>
</div>


<script type="text/javascript" src="../interactive/DataStructures/huffman.js"></script>
<script type="text/javascript" src="../interactive/Binary/huffmanLabelCON.js"></script>
<script>
  $(document).ready(function(){
    function NewAV() {return new JSAV("huffmanLabelCON", {animationMode: "none"})}
    function AddCSS(rule) {document.getElementById("dynamicStyleSheet").sheet.insertRule("#huffmanLabelCON "+rule)}
    
  });
</script>

</details>
</div>
<p>Now that we see how the edges associate with bits in the code, it is
a simple matter to generate the codes for each character (since each
character corresponds to a leaf node in the tree).</p>
<div class="dsvis">
<details open="true">
<summary>
<p>Here is an illustration of how to transform the Huffman tree for our
running example into bit codes.</p>
</summary>

<div id="huffmanCodesCON" class="ssAV" data-short-name="huffmanCodesCON" data-long-name="Huffman Coding Tree Slideshow: Setting Codes" alt="Huffman Coding Tree Slideshow: Setting Codes" tabIndex="-1">
<span class="jsavcounter"></span>
<div class="jsavcontrols"></div>
<p class="jsavoutput jsavline"></p>
<div class="jsavcanvas"></div>
</div>


<script type="text/javascript" src="../interactive/DataStructures/huffman.js"></script>
<script type="text/javascript" src="../interactive/Binary/huffmanCodesCON.js"></script>
<script>
  $(document).ready(function(){
    function NewAV() {return new JSAV("huffmanCodesCON", {animationMode: "none"})}
    function AddCSS(rule) {document.getElementById("dynamicStyleSheet").sheet.insertRule("#huffmanCodesCON "+rule)}
    
  });
</script>

</details>
</div>
<p>Now that we have a code for each character, encoding a text message
is done by replacing each character of the message with its binary code.
A lookup table can be used for this purpose.</p>
</section>
<section id="sec:decoding" class="level3" data-number="9.4.4">
<h3 data-number="9.4.4"><span class="header-section-number">9.4.4</span>
Decoding</h3>
<p>A set of codes is said to meet the <a
href="section-14.html#prefix-property" class="term"
title="Given a collection of strings, the collection has the prefix property if no string in the collection is a prefix for another string in the collection. The significance is that, given a long string composed of members of the collection, it can be uniquely decomposed into the constituent members. An example of such a collection of strings with the prefix property is a set of Huffman codes.">prefix
property</a> if no code in the set is the prefix of another. The prefix
property guarantees that there will be no ambiguity in how a bit string
is decoded. In other words, once we reach the last bit of a code during
the decoding process, we know which character it is the code for.
Huffman codes certainly have the prefix property because any prefix for
a code would correspond to an internal node, while all codes correspond
to leaf nodes.</p>
<p>When we decode a character using the Huffman coding tree, we follow a
path through the tree dictated by the bits in the code string. Each ‚Äò0‚Äô
bit indicates a left branch while each ‚Äò1‚Äô bit indicates a right
branch.</p>
<div class="dsvis">
<details open="true">
<summary>
<p>The following slideshow shows how to decode a message by traversing
our example Huffman tree.</p>
</summary>

<div id="huffmanDecodeCON" class="ssAV" data-short-name="huffmanDecodeCON" data-long-name="Huffman Coding Tree Slideshow: Decoding" alt="Huffman Coding Tree Slideshow: Decoding" tabIndex="-1">
<span class="jsavcounter"></span>
<div class="jsavcontrols"></div>
<p class="jsavoutput jsavline"></p>
<div class="jsavcanvas"></div>
</div>


<script type="text/javascript" src="../interactive/DataStructures/huffman.js"></script>
<script type="text/javascript" src="../interactive/Binary/huffmanDecodeCON.js"></script>
<script>
  $(document).ready(function(){
    function NewAV() {return new JSAV("huffmanDecodeCON", {animationMode: "none"})}
    function AddCSS(rule) {document.getElementById("dynamicStyleSheet").sheet.insertRule("#huffmanDecodeCON "+rule)}
    
  });
</script>

</details>
</div>
<div class="dsvis">
<details open="true">
<summary>
<section id="sec:practice-exercise-huffman-decoding"
class="level4 unnumbered">
<h4 class="unnumbered">Practice exercise: Huffman decoding</h4>
</summary>

<div id="HuffmanDecodePRO" class="embedContainer">
<iframe id="HuffmanDecodePRO_iframe" aria-label="HuffmanDecodePRO" src="../interactive/Binary/HuffmanDecodePRO.html" width="100%" height="600" scrolling="no">
Your browser does not support iframes.
</iframe>
</div>

</details>
</section>
</div>
</section>
<section id="sec:how-efficient-is-huffman-coding" class="level3"
data-number="9.4.5">
<h3 data-number="9.4.5"><span class="header-section-number">9.4.5</span>
How efficient is Huffman coding?</h3>
<p>In theory, Huffman coding is an optimal coding method whenever the
true frequencies are known, and the frequency of a letter is independent
of the context of that letter in the message. In practice, the
frequencies of letters in an English text document do change depending
on context. For example, while E is the most commonly used letter of the
alphabet in English documents, T is more common as the first letter of a
word. This is why most commercial compression utilities do not use
Huffman coding as their primary coding method, but instead use
techniques that take advantage of the context for the letters.</p>
<p>Another factor that affects the compression efficiency of Huffman
coding is the relative frequencies of the letters. Some frequency
patterns will save no space as compared to fixed-length codes; others
can result in great compression. In general, Huffman coding does better
when there is large variation in the frequencies of letters.</p>
<p>The average expected cost per letter,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>,
is the sum of the cost for each letter
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mi>i</mi></msub><annotation encoding="application/x-tex">c_i</annotation></semantics></math>)
times the probability of its occurring
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>p</mi><mi>i</mi></msub><annotation encoding="application/x-tex">p_i</annotation></semantics></math>),
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mn>1</mn></msub><msub><mi>p</mi><mn>1</mn></msub><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub><msub><mi>p</mi><mn>2</mn></msub><mo>+</mo><mi>‚ãØ</mi><mo>+</mo><msub><mi>c</mi><mi>n</mi></msub><msub><mi>p</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">c_1 p_1 + c_2 p_2 + \cdots + c_n p_n</annotation></semantics></math>.
Usually we measure the cost as the number of <em>bits</em> that is
needed to encode one letter. The formula can be reorganised as follows,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>i</mi></msub><annotation encoding="application/x-tex">f_i</annotation></semantics></math>
is the (relative) frequency of letter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>T</mi></msub><annotation encoding="application/x-tex">f_T</annotation></semantics></math>
is the total for all letter frequencies:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mrow><msub><mi>c</mi><mn>1</mn></msub><msub><mi>f</mi><mn>1</mn></msub><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub><msub><mi>f</mi><mn>2</mn></msub><mo>+</mo><mi>‚ãØ</mi><mo>+</mo><msub><mi>c</mi><mi>n</mi></msub><msub><mi>f</mi><mi>n</mi></msub></mrow><msub><mi>f</mi><mi>T</mi></msub></mfrac><annotation encoding="application/x-tex">
\frac{c_1 f_1 + c_2 f_2 + \cdots + c_n f_n}{f_T}
</annotation></semantics></math></p>
<section id="sec:example-expected-savings"
class="level4 unnumbered example">
<h4 class="unnumbered">Example: Expected savings</h4>
<p>Let‚Äôs repeat the frequencies and the Huffman codes for each of the
letters in our running example:</p>
<table>
<tbody>
<tr>
<td style="text-align: left;"><strong>Letter</strong></td>
<td style="text-align: center;">C</td>
<td style="text-align: center;">D</td>
<td style="text-align: center;">E</td>
<td style="text-align: center;">K</td>
<td style="text-align: center;">L</td>
<td style="text-align: center;">M</td>
<td style="text-align: center;">U</td>
<td style="text-align: center;">Z</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Frequency</strong></td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Code</strong></td>
<td style="text-align: center;">1110</td>
<td style="text-align: center;">101</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">111101</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">11111</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">111100</td>
</tr>
</tbody>
</table>
<p>The sum of the letter frequencies is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>T</mi></msub><mo>=</mo><mn>306</mn></mrow><annotation encoding="application/x-tex">f_T = 306</annotation></semantics></math>,
and the cost of each letter is the number bits in their code. For
example, the cost of E is 1 and the cost of K and Z are 6 each. Now we
can calculate the expected cost per letter using the formula above:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mn>4</mn><mo>√ó</mo><mn>32</mn><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>3</mn><mo>√ó</mo><mn>42</mn><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>√ó</mo><mn>120</mn><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>6</mn><mo>√ó</mo><mn>7</mn><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>3</mn><mo>√ó</mo><mn>42</mn><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>5</mn><mo>√ó</mo><mn>24</mn><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>3</mn><mo>√ó</mo><mn>37</mn><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>6</mn><mo>√ó</mo><mn>2</mn><mo stretchy="false" form="postfix">)</mo></mrow><mn>306</mn></mfrac><mspace width="0.278em"></mspace><mo>=</mo><mspace width="0.278em"></mspace><mfrac><mn>785</mn><mn>306</mn></mfrac><mspace width="0.278em"></mspace><mo>‚âà</mo><mspace width="0.278em"></mspace><mn>2.57</mn></mrow><annotation encoding="application/x-tex">
\frac{
(4 \times 32) + (3 \times 42) + (1 \times 120) + (6 \times 7) + (3 \times 42) + (5 \times 24) + (3 \times 37) + (6 \times 2)
}{306}
\;=\; \frac{785}{306} \;\approx\; 2.57
</annotation></semantics></math></p>
<p>A fixed-length code for these eight letters would require
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>log</mi><mo>&#8289;</mo></mrow><mn>8</mn><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\log 8 = 3</annotation></semantics></math>
bits per letter as opposed to about 2.57 bits per letter for Huffman
coding. Thus, Huffman coding is expected to save about 14% for this set
of letters.</p>
</section>
<p>Huffman coding for all Latin-1 symbols should do better than the
8-letter example. The letter frequencies are atypical in that there are
too many common letters compared to the number of rare letters.</p>
<p>Huffman coding of a normal English text usually yields an expected
cost of around 4.5 bits per character, compared to the standard way of
encoding each letter in 8 bits. So, Huffman coding of a typical English
text file will save at least 40% over Latin-1 coding. Huffman coding for
a binary file (such as a compiled executable, an image or a video) would
have a very different set of distribution frequencies and so would have
a different space savings. Most state-of-the-art compression programs
use two or three coding schemes to adjust to different types of
files.</p>
<p>In decoding example, ‚ÄúDEED‚Äù was coded in 8 bits, a saving of 33% over
the twelve bits required from a fixed-length coding. However, ‚ÄúMUCK‚Äù
would require 18 bits, more space than required by the corresponding
fixed-length coding. The problem is that ‚ÄúMUCK‚Äù is composed of letters
that are not expected to occur often. If the message does not match the
expected frequencies of the letters, than the length of the encoding
will not be as expected either.</p>
<div class="dsvis">
<details open="true">
<summary>
<p>You can use the following visualisation to create a Huffman tree for
your own set of letters and frequencies.</p>
</summary>

<div id="huffmanCustomBuildAV" class="embedContainer">
<iframe id="huffmanCustomBuildAV_iframe" aria-label="huffmanCustomBuildAV" src="../interactive/Binary/huffmanCustomBuildAV.html" width="100%" height="600" scrolling="no">
Your browser does not support iframes.
</iframe>
</div>

</details>
</div>
</section>
<section id="sec:proof-of-optimality-for-huffman-coding" class="level3"
data-number="9.4.6">
<h3 data-number="9.4.6"><span class="header-section-number">9.4.6</span>
Proof of optimality for Huffman coding</h3>
<p>Huffman tree building is an example of a <a
href="section-14.html#greedy-algorithm" class="term"
title="An algorithm that makes locally optimal choices at each step.">greedy
algorithm</a>. At each step, the algorithm makes a ‚Äúgreedy‚Äù decision to
merge the two subtrees with least weight. This makes the algorithm
simple, but does it give the desired result? This concludes with a proof
that the Huffman tree indeed gives the most efficient arrangement for
the set of letters. The proof requires the following lemma.</p>
<div class="topic">
<p><strong>Lemma:</strong> For any Huffman tree built by function
<code>buildHuffmanTree</code> containing at least two letters, the two
letters with least frequency are stored in sibling nodes whose depth is
at least as deep as any other leaf nodes in the tree.</p>
<p><strong>Proof:</strong> Call the two letters with least frequency
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>1</mn></msub><annotation encoding="application/x-tex">l_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>2</mn></msub><annotation encoding="application/x-tex">l_2</annotation></semantics></math>.
They must be siblings because <code>buildHuffmanTree</code> selects them
in the first step of the construction process. Assume that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>1</mn></msub><annotation encoding="application/x-tex">l_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>2</mn></msub><annotation encoding="application/x-tex">l_2</annotation></semantics></math>
are not the deepest nodes in the tree. In this case, the Huffman tree
must either look like in the figure below, or effectively symmetrical to
this. For this situation to occur, the parent of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>1</mn></msub><annotation encoding="application/x-tex">l_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>2</mn></msub><annotation encoding="application/x-tex">l_2</annotation></semantics></math>,
labeled
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>,
must have greater weight than the node labeled
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>.
Otherwise, function <code>buildHuffmanTree</code> would have selected
node
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>
in place of node
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
as the child of node
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>U</mi><annotation encoding="application/x-tex">U</annotation></semantics></math>.
However, this is impossible because
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>1</mn></msub><annotation encoding="application/x-tex">l_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>2</mn></msub><annotation encoding="application/x-tex">l_2</annotation></semantics></math>
are the letters with least frequency.</p>
<p>This figure shows an impossible Huffman tree, where the two nodes
with least weight,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>1</mn></msub><annotation encoding="application/x-tex">l_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>l</mi><mn>2</mn></msub><annotation encoding="application/x-tex">l_2</annotation></semantics></math>,
are not the deepest nodes in the tree. Triangles represent subtrees.</p>

<div id="HuffProofCON" class="ssAV" data-short-name="HuffProofCON" data-long-name="HuffProofCON" alt="HuffProofCON" tabIndex="-1">
<div class="jsavcanvas"></div>
</div>

<script type="text/javascript" src="../interactive/Binary/HuffProofCON.js"></script>
<script>
  $(document).ready(function(){
    function NewAV() {return new JSAV("HuffProofCON", {animationMode: "none"})}
    function AddCSS(rule) {document.getElementById("dynamicStyleSheet").sheet.insertRule("#HuffProofCON "+rule)}
    
  });
</script>

</div>
<p>Using this lemma we can prove the following theorem:</p>
<div class="topic">
<p><strong>Theorem:</strong> Function <code>buildHuffmanTree</code>
builds the Huffman tree with the minimum external path weight for the
given set of letters.</p>
<p><strong>Proof:</strong> The proof is by induction on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>,
the number of letters.</p>
<ul>
<li><strong>Base Case:</strong> For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n = 2</annotation></semantics></math>,
the Huffman tree must have the minimum external path weight because
there are only two possible trees, each with identical weighted path
lengths for the two leaves.</li>
<li><strong>Induction Hypothesis:</strong> Assume that any tree created
by <code>buildHuffmanTree</code> that contains
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>‚àí</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math>
leaves has minimum external path length.</li>
<li><strong>Induction Step:</strong> Given a Huffman tree
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêì</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>
built by <code>buildHuffmanTree</code> with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
leaves,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>‚â•</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n \geq 2</annotation></semantics></math>,
suppose that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>‚â§</mo><msub><mi>w</mi><mn>2</mn></msub><mo>‚â§</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>‚â§</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">w_1 \leq w_2 \leq ... \leq w_n</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>1</mn></msub><annotation encoding="application/x-tex">w_1</annotation></semantics></math>
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>n</mi></msub><annotation encoding="application/x-tex">w_n</annotation></semantics></math>
are the weights of the letters. Call
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>
the parent of the letters with frequencies
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>1</mn></msub><annotation encoding="application/x-tex">w_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>2</mn></msub><annotation encoding="application/x-tex">w_2</annotation></semantics></math>.
From the lemma, we know that the leaf nodes containing the letters with
frequencies
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>1</mn></msub><annotation encoding="application/x-tex">w_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>2</mn></msub><annotation encoding="application/x-tex">w_2</annotation></semantics></math>
are as deep as any nodes in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêì</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>.
If any other leaf nodes in the tree were deeper, we could reduce their
weighted path length by swapping them with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>1</mn></msub><annotation encoding="application/x-tex">w_1</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>2</mn></msub><annotation encoding="application/x-tex">w_2</annotation></semantics></math>.
But the lemma tells us that no such deeper nodes exist. Call
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ùêì</mi><mo>‚Ä≤</mo></msup><annotation encoding="application/x-tex">\mathbf{T}&#39;</annotation></semantics></math>
the Huffman tree that is identical to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêì</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>
except that node
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>
is replaced with a leaf node
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>V</mi><mo>‚Ä≤</mo></msup><annotation encoding="application/x-tex">V&#39;</annotation></semantics></math>
whose weight is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_1 + w_2</annotation></semantics></math>.
By the induction hypothesis,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ùêì</mi><mo>‚Ä≤</mo></msup><annotation encoding="application/x-tex">\mathbf{T}&#39;</annotation></semantics></math>
has minimum external path length. Returning the children to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>V</mi><mo>‚Ä≤</mo></msup><annotation encoding="application/x-tex">V&#39;</annotation></semantics></math>
restores tree
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêì</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>,
which must also have minimum external path length.</li>
</ul>
<p>Thus by mathematical induction, function
<code>buildHuffmanTree</code> creates the Huffman tree with minimum
external path length.</p>
</div>
</section>
</div>
</section>
</main>

<footer>
<nav class="sitenav">
<div class="navlink">
<a href="section-9.3.html" class="navbutton">&lt;&lt;</a>
<a href="section-9.3.html" accesskey="p" rel="previous">Case study: Heapsort</a>
</div>
<div class="navlink">
<a href="section-9.5.html" accesskey="n" rel="next">Review questions</a>
<a href="section-9.5.html" class="navbutton">&gt;&gt;</a>
</div>
</nav>
</footer>

</body>
</html>


